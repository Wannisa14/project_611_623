{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1wNHzvjm-gJHBQUVdz3OZhxll9mEZKwpn","timestamp":1702282293215},{"file_id":"1HFY6gwM-y2TqktOyPB7otkAKZaRfwUDj","timestamp":1702182817195},{"file_id":"1YQ_SkPxMKONc9WNnRViA3igl1uHNzoHv","timestamp":1702106810999},{"file_id":"1llweNV2SFV6clMaw4R7ywxaf29uShbgJ","timestamp":1702027850102}],"authorship_tag":"ABX9TyNLMiF4WEmrgNuf8wQCHqOL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import necessary libraries"],"metadata":{"id":"7MLzhmrl-OXY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"84VvA59qrDm8"},"outputs":[],"source":["from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.optimizers import Adam\n","\n","# Data Processing\n","import numpy as np\n","import pandas as pd\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from plotly.subplots import make_subplots\n","import plotly.graph_objects as go\n","import plotly.io as pi\n","import plotly.express as px\n","\n","import math\n","\n"]},{"cell_type":"code","source":["# Accessing My Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTfwUW-BrH2I","executionInfo":{"status":"ok","timestamp":1702107382249,"user_tz":-420,"elapsed":19661,"user":{"displayName":"WANNISA CHEAMSIRI","userId":"01956088230017453516"}},"outputId":"fdd114f6-463f-4811-b417-99e5cee0c481"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#Data Collection"],"metadata":{"id":"CD6VAE3Sdf18"}},{"cell_type":"markdown","source":["Load the dataset"],"metadata":{"id":"9eMsbU2_-TRB"}},{"cell_type":"code","source":["# Step 1: Data Collection\n","df = pd.read_csv('/content/drive/MyDrive/Classroom/EGCO623_T1 2023 Master/Project/EURJPY.csv')\n","print(df.shape)"],"metadata":{"id":"rL8ROfvDrNyn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data Describtion"],"metadata":{"id":"bnVLk39m-WRQ"}},{"cell_type":"code","source":["df.head(5)"],"metadata":{"id":"po_imz81rf2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.tail(5)"],"metadata":{"id":"cNA8aVLX5Ri2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.info()"],"metadata":{"id":"n0NHwiODruCr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data cleaning"],"metadata":{"id":"eBBV3UrW-g2k"}},{"cell_type":"code","source":["# Check Is there any null values in the Dataset\n","df.isnull().sum()"],"metadata":{"id":"kgqKIvB0r7QD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the Duplicate value in the Dataset\n","df.duplicated().sum()"],"metadata":{"id":"gesF1xOE5bPZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T1kF2FfKNojn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data transformation"],"metadata":{"id":"kri02rv9-maC"}},{"cell_type":"code","source":["# convert 'Date' dtype to datatime\n","df[\"From\"] = pd.to_datetime(df[\"From\"])\n","df[\"To\"] = pd.to_datetime(df[\"To\"])\n","# check\n","df.info()"],"metadata":{"id":"ViGcJc86rxC2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.describe().round(6).T #round(6) ทศนิยม 6 ตำแหน่ง"],"metadata":{"id":"p5fCkMg4r9ki"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Some observation from the data statitics:\n","1. There are 110,000 observations in the dataset.\n","2. The minimum and maximum values for Open, High, Low, Close, and Adj Close prices are significantly different,   indicating a large range of values for these variables.\n","3. The volume values in the dataset also have a large range of values, with a mean value of 1170.96."],"metadata":{"id":"Viyyh2y_wAj2"}},{"cell_type":"markdown","source":["#EDA"],"metadata":{"id":"v5uYCYcgsC20"}},{"cell_type":"code","source":["fig = px.line(df, x='From', y='Close', title='Closing Prices Over Time - EURJPY')\n","fig.update_xaxes(title='Date')\n","fig.update_yaxes(title='Closing Price')\n","fig.update_layout(template='plotly_dark')\n","fig.show()"],"metadata":{"id":"NtjlgtfdtYXz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Visualize the Correlation Matrix"],"metadata":{"id":"ub-ciqFs_SUK"}},{"cell_type":"code","source":["# Lets Visualise the Correlation Matrix\n","plt.figure(figsize=(5,3))\n","sns.heatmap(df.corr(), fmt=\".2f\", annot=True, cmap='Greens')\n","plt.title(f'Correlation Matrix - EURJPY')\n","plt.show()"],"metadata":{"id":"_aNoQZcl2Jty"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Heatmap of correlation between features:\n","* Shows the correlation between all the features in the dataset\n","* Indicates that the Close Price has a strong positive correlation with Open, High, and Low, but a weak negative correlation with Volume\n","* Also indicates that the Open, High, and Low are highly correlated with each other"],"metadata":{"id":"ItIztEAmxB-w"}},{"cell_type":"code","source":["# Pairplot of features\n","\n","sns.pairplot(data=df, vars=['Open', 'High', 'Low', 'Close', 'Volume'])\n","plt.title('Pairplot of Features - EURJPY')\n","plt.show()"],"metadata":{"id":"5ksU78TN-9m1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Pairplot of features:\n","* Shows the pairwise relationships between all the features in the dataset\n","\n","* Indicates that the Open, High, and Low are strongly positively correlated with each other, with a linear relationship\n","\n","* Also indicates that the Volume feature is not strongly correlated with any of the other features"],"metadata":{"id":"gzMQr3R6xcJs"}},{"cell_type":"code","source":["# Create a line chart using the dataset with two lines, 'High' and 'Low' on the y-axis\n","\n","list1=[\"Open\",\"High\",\"Low\",\"Close\"]\n","list2=[\"High\", \"Low\"]\n","list3=[\"Open\",\"Close\"]\n","list4=[list1, list2, list3]\n","\n","\n","for i in range(len(list4)):\n","    fig = px.line(df, x=\"From\", y=list4[i], title=\"Distribution over Different Time Window - EURJPY\")\n","\n","    # Update the x-axis settings to include a range slider\n","    # This allows users to zoom in on specific date ranges\n","    fig.update_xaxes(\n","    rangeslider_visible=True,\n","\n","    # Configure a rangeselector with buttons for different time intervals\n","    rangeselector=dict(\n","    buttons=list([\n","    dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n","    dict(count=6, label=\"6m\", step=\"month\", stepmode=\"backward\"),\n","    dict(count=1, label=\"1Y\", step=\"year\", stepmode=\"todate\"),\n","    dict(step=\"all\")\n","    ])\n","    )\n","    )\n","\n","  # Display the figure\n","    fig.show()"],"metadata":{"id":"CkJDCBji9BHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_transformed = pd.DataFrame()"],"metadata":{"id":"g4Ho3KWWs7zB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_transformed['From'] = df['From']\n","\n","# log transformation and check\n","for col in ['Open', 'Close', 'Low', 'High', 'Volume']:\n","    df_transformed[col] = np.log1p(df[col])"],"metadata":{"id":"YnNLrdbKtFEh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_transformed.shape"],"metadata":{"id":"H-g0LuRPz9GN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Preprocessing"],"metadata":{"id":"cy8xSPd3FFdJ"}},{"cell_type":"code","source":["# Normalize\n","scaler_x = MinMaxScaler() #x\n","scaler_y = MinMaxScaler() #Y\n","#scaler = MinMaxScaler()"],"metadata":{"id":"1yfT2r7wtcgu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data Normalization"],"metadata":{"id":"n9bN6Lbsyayt"}},{"cell_type":"code","source":["# scaling\n","def scale_data(data):\n","\n","    arr_x = scaler_x.fit_transform(data.drop(['From','Close'], axis=1).values)\n","    arr_y = scaler_y.fit_transform(data['Close'].values.reshape(-1, 1))\n","\n","    arr_result = np.concatenate([arr_y, arr_x], 1)\n","\n","    return arr_result"],"metadata":{"id":"rUR3nKVWtfsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr_transformed = scale_data(df_transformed)"],"metadata":{"id":"YxDgIRr9tjl_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr_transformed"],"metadata":{"id":"yiE0aXDIsOr4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["arr_transformed.shape"],"metadata":{"id":"jBAX4SoVvCOh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function that make sequence data\n","def create_sequences(data, seq_length):\n","    X, y = [], []\n","\n","    for i in range(len(data) - seq_length):\n","        X.append(data[i:i + seq_length]) # data of past candles\n","        y.append(data[i + seq_length][0]) # 'Close' of next candle\n","\n","    return np.array(X), np.array(y)"],"metadata":{"id":"bMHBOdSTvuiB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["seq_length = 10  # the number of past candles to be used for predictions\n","X, y = create_sequences(arr_transformed, seq_length)"],"metadata":{"id":"BHJejNBhvxKR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.shape"],"metadata":{"id":"COc_w21CFDiO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y.shape"],"metadata":{"id":"4OsUakXdXvKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Data Splitting"],"metadata":{"id":"VIjaX2s1yVv1"}},{"cell_type":"code","source":["# split\n","# train_size = int(len(X) * 0.70)\n","# X_train, y_train = X[:train_size], y[:train_size]\n","# X_test, y_test = X[train_size:], y[train_size:]\n","\n","train_size = int(len(X) * 0.7)\n","val_size = int(len(X) * 0.1)\n","test_size = len(X) - train_size - val_size\n","X_train, y_train = X[:train_size], y[:train_size]\n","X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n","X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n"],"metadata":{"id":"rDXq6lW-v3cD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"X_train: {X_train.shape}, y_train:{y_train.shape}\")\n","print(f\"X_val: {X_val.shape}, y_val:{y_val.shape}\")\n","print(f\"X_test: {X_test.shape}, y_test:{y_test.shape}\")"],"metadata":{"id":"coKbZH_NxVF2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model Training"],"metadata":{"id":"hB5XywIFFewo"}},{"cell_type":"markdown","source":["# LSTM"],"metadata":{"id":"ejhkDCfSKGrY"}},{"cell_type":"code","source":["# LSTM\n","model_LSTM = Sequential([\n","    LSTM(units = 50, activation = 'relu', return_sequences = True, input_shape = (seq_length, 5)),\n","    LSTM(units = 50, activation = 'relu', return_sequences = False),\n","    Dense(units = 1)\n","\n","])\n","\n","model_LSTM.compile(optimizer = 'adam', loss = 'mean_squared_error')"],"metadata":{"id":"jep2GU3__4QX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_LSTM.summary()"],"metadata":{"id":"g_rBBQoi_-Wy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_LSTM_history = model_LSTM.fit(\n","    X_train, y_train,\n","    epochs = 30,\n","    batch_size = 128,\n","    validation_data = (X_val, y_val)\n",")\n"],"metadata":{"id":"JMNH4Mf4v9Aw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the trained model\n","model_LSTM.save('EURJPY_LSTM.h5')"],"metadata":{"id":"m9rCwMpUksKD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss curve\n","plt.figure(figsize = (5, 3))\n","\n","plt.plot(model_LSTM_history.history['loss'], color = \"blue\")\n","plt.plot(model_LSTM_history.history['val_loss'], color = \"orange\")\n","\n","plt.title('Loss curve - EURJPY')\n","plt.xlabel(\"epoch\")\n","plt.ylabel(\"loss\")\n","plt.legend(['loss','val_loss'])\n","\n","plt.show()"],"metadata":{"id":"heyuD60CwFT7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation"],"metadata":{"id":"MVHaKv8FAzLn"}},{"cell_type":"markdown","source":["#LSTM"],"metadata":{"id":"ILkxVuTCHYod"}},{"cell_type":"code","source":["# prediction\n","train_predict=model_LSTM.predict(X_train)\n","val_predict=model_LSTM.predict(X_val)\n","test_predict=model_LSTM.predict(X_test)\n","#y_pred= np.concatenate([model_LSTM.predict(X_train),model_LSTM.predict(X_val), model_LSTM.predict(X_test)])\n","y_pred= np.concatenate([train_predict,val_predict, test_predict])\n","y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n","y_pred_rescaled = np.expm1(y_pred_rescaled)"],"metadata":{"id":"z5BSAm29wNJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# inverse scaling: actual y\n","y_rescaled = np.expm1(scaler_y.inverse_transform(y.reshape(-1, 1)))"],"metadata":{"id":"UZDjgp57wYLO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate the performance indicators\n","mae = mean_absolute_error(y_test, test_predict)\n","mse= mean_squared_error(y_test, test_predict)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_test, test_predict)\n","mape = mean_absolute_percentage_error(y_test, test_predict)\n","mfe = np.mean(test_predict - y_test)\n","# actual_diff = np.diff(y_test)\n","# mase = np.mean(np.abs(y_pred - y_test)) / np.mean(np.abs(actual_diff))"],"metadata":{"id":"jpjIKHe3IPPG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Print the performance indicators\n","# Mean Absolute Error (MAE): This measures the average absolute errors between actual and predicted values. It gives an idea of the magnitude of the errors.\n","print('MAE:', mae)\n","# Mean Squared Error (MSE): This measures the average of the squares of the errors. It penalizes larger errors more than smaller ones.\n","print('MSE:', mse)\n","# Root Mean Squared Error (RMSE): This is the square root of the MSE and provides an interpretable scale for the errors.\n","print('RMSE:', rmse)\n","# R-squared (R2): This measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n","# It provides an indication of the goodness of fit of the model.\n","print('R-squared:', r2)\n","# Mean Absolute Percentage Error (MAPE): This measures the average of the absolute percentage differences between actual and predicted values.\n","# It is useful for understanding the accuracy of the model's predictions.\n","print('MAPE:', mape)\n","# Mean Forecast Error (MFE): This measures the average of the forecast errors.\n","# A positive MFE indicates that the forecasts are, on average, too low, while a negative MFE indicates that the forecasts are, on average, too high.\n","print('MFE:', mfe)\n","# print('MASE:', mase)"],"metadata":{"id":"TwfsRoduI41k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#y_pred= np.concatenate([model_LSTM.predict(X_train),model_LSTM.predict(X_val), model_LSTM.predict(X_test)])\n","y_pred= np.concatenate([train_predict, val_predict, test_predict])\n","y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n","y_pred_rescaled = np.expm1(y_pred_rescaled)\n","\n","train_predict = scaler_y.inverse_transform(train_predict)\n","train_predict = np.expm1(train_predict)\n","#train_predict = np.expm1(scaler_y.inverse_transform(y.reshape(-1, 1)))\n","\n","val_predict = scaler_y.inverse_transform(val_predict)\n","val_predict = np.expm1(val_predict)\n","#val_predict = np.expm1(scaler_y.inverse_transform(y.reshape(-1, 1)))\n","\n","test_predict = scaler_y.inverse_transform(test_predict)\n","test_predict = np.expm1(test_predict)\n","#test_predict = np.expm1(scaler_y.inverse_transform(y.reshape(-1, 1)))"],"metadata":{"id":"xQmOBQH2C6wC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting the baseline data, training predictions, and test predictions\n","plt.figure(figsize=(15, 6))\n","plt.plot(y_rescaled, color='black', label=f\"Actual Close price\")\n","plt.plot(y_pred_rescaled, color='blue', label=f\"Predicted Close price\", linestyle = \"--\")\n","\n","plt.title(f\"Close Price - EURJPY\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(f\"Close Price\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"86HKO0l5e7xN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = make_subplots(rows=1, cols=1, subplot_titles=('Close Predictions - EURJPY'))\n","\n","train_close_pred = y_pred_rescaled[:, 0]\n","train_close_actual = y_rescaled[:, 0]\n","\n","fig.add_trace(go.Scatter(x=np.arange(len(train_close_actual)), y=train_close_actual, mode='lines', name='Actual', opacity=0.9))\n","fig.add_trace(go.Scatter(x=np.arange(len(train_close_pred)), y=train_close_pred, mode='lines', name='Predicted', opacity=0.6))\n","\n","fig.update_layout(title='Close Predictions', template='plotly_dark')\n","fig.show()"],"metadata":{"id":"kt_aoEA_1xQf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting the baseline data, training predictions, and test predictions\n","plt.figure(figsize=(15, 6))\n","plt.plot(y_rescaled, color='black', label=f\"Actual Close price\")\n","plt.plot(train_predict, color='blue', label=f\"Predicted Close price(train set)\", linestyle = \"--\")\n","plt.plot(np.concatenate([np.full_like(train_predict, np.nan), val_predict]), color='red', label=f\"Predicted Close price(validat set)\", linestyle = \"--\")\n","plt.plot(np.concatenate([np.full_like(train_predict, np.nan),np.full_like(val_predict, np.nan), test_predict]), color='green', label=f\"Predicted Close price(test set)\", linestyle = \"--\")\n","\n","plt.title(f\"Close Price - EURJPY\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(f\"Close Price\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"_tJxgys4B77W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = make_subplots(rows=1, cols=1, subplot_titles=('Close Predictions - EURJPY'))\n","\n","train_close_actual = y_rescaled[:, 0]\n","train_pred = train_predict[:, 0]\n","val_pred = val_predict[:, 0]\n","test_pred = test_predict[:, 0]\n","\n","# Create the extended x-axis for val_pred\n","train_x = df['From'][:len(train_pred)]\n","val_x = df['From'][len(train_pred):len(train_pred)+len(val_pred)]\n","test_x = df['From'][len(train_pred)+len(val_pred):]\n","\n","fig.add_trace(go.Scatter(x=df['From'], y=train_close_actual, mode='lines', name='Actual', opacity=0.9, line=dict(color='black')))\n","fig.add_trace(go.Scatter(x=train_x, y=train_pred, mode='lines', name='Train Predicted', opacity=0.6, line=dict(dash='dash',color='blue')))\n","fig.add_trace(go.Scatter(x=val_x, y=val_pred, mode='lines', name='Val Predicted', opacity=0.6, line=dict(dash='dash',color='red')))\n","fig.add_trace(go.Scatter(x=test_x, y=test_pred, mode='lines', name='Test Predicted', opacity=0.6, line=dict(dash='dash',color='green')))\n","\n","fig.update_layout(title='Close Predictions - EURJPY', template='plotly_white')\n","fig.show()"],"metadata":{"id":"zlEZovzC8JlB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting the baseline data, training predictions, and test predictions\n","plt.figure(figsize=(15, 6))\n","plt.plot(np.concatenate([np.full_like(train_predict, np.nan),y_rescaled[len(train_predict):]]), color='black', label=f\"Actual Close price\")\n","plt.plot(np.concatenate([np.full_like(train_predict, np.nan), val_predict]), color='red', label=f\"Predicted Close price(validat set)\", linestyle = \"--\")\n","plt.plot(np.concatenate([np.full_like(train_predict, np.nan),np.full_like(val_predict, np.nan), test_predict]), color='green', label=f\"Predicted Close price(test set)\", linestyle = \"--\")\n","\n","plt.title(f\"Close Price - EURJPY\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(f\"Close Price\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"VmhUA8RThJwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df for analyze residual\n","df_LSTM_diff = pd.concat([pd.DataFrame(y_rescaled, columns = ['Close_actual']),\n","                               pd.DataFrame(y_pred_rescaled, columns = ['Close_pred'])],\n","                              axis = 1)\n","df_LSTM_diff['From'] = df['From']\n","df_LSTM_diff['resid'] = df_LSTM_diff['Close_pred'] - df_LSTM_diff['Close_actual']\n","\n","# check\n","df_LSTM_diff.head(10)"],"metadata":{"id":"typrvME4wpot"},"execution_count":null,"outputs":[]}]}